{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4176c059-3c12-483d-a793-42cbe8fb331b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#!pip unistall -y transformers\n",
    "!pip install -U -q transformers\n",
    "!pip install -q accelerate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "136f6971-ef05-46c9-b3cd-27f6bbf4af9e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.11/site-packages/torch/_utils.py:831: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()\n",
      "  return self.fget.__get__(instance, owner)()\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n"
     ]
    }
   ],
   "source": [
    "## Load dolly-v2 from huggingface\n",
    "from transformers import pipeline\n",
    "import torch\n",
    "dolly_pipeline = pipeline(model=\"databricks/dolly-v2-3b\", torch_dtype=torch.bfloat16, trust_remote_code=True)\n",
    "#dolly_pipeline = pipeline(model=\"databricks/dolly-v2-3b\", torch_dtype=torch.bfloat16, trust_remote_code=True, device_map=\"auto\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3bf395df-4000-463d-91bc-d9b9ea45b8be",
   "metadata": {},
   "source": [
    "## Prepare prompt template for fake statement detection\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "434e569c-8ec5-4f3d-a6ac-847fc460c6d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def get_completion_dolly(statement,context):\n",
    "\n",
    "  prompt = f\"\"\"Determine if the given statement is fake, based on the context below.\n",
    "  If you don't know, say that you do not know.\n",
    "\n",
    "  Use only information from the context to make the judgement and answer the question at the end.\n",
    "\n",
    "  Statement:\n",
    "  {statement}\n",
    "\n",
    "  Context:\n",
    "  {context}\n",
    "\n",
    "  Response:\n",
    "  \"\"\"\n",
    "\n",
    "  #print(prompt)\n",
    "  #dolly_response = dolly_pipeline(prompt, max_new_tokens=50, temperature=0.2, top_p=0.3)\n",
    "  dolly_response = dolly_pipeline(prompt, max_time=10, max_new_tokens=100, temperature=0.4, top_p=0.55)\n",
    "  return dolly_response #[0][\"generated_text\"]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f94c47d3-2257-4f27-9556-0d494915a0c3",
   "metadata": {},
   "source": [
    "### Prepare the following testcases to test the above prompt and the responses from Dolly\n",
    "* Will run the same prompt few times to get the probability of getting consistent results\n",
    "* It takes about 4G ram and even run faster with T4 GPU on colab\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3756037e-208e-4301-9fca-6f09cfd4ee45",
   "metadata": {},
   "source": [
    "### Case 1: A fake statement with authorized context found online\n",
    "* Expect to flag fake\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "10a86568-60c9-4e35-aaac-8f63141c628e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 0\n",
      "The statement is fake. The statement is an apparent imitation or digital manipulation of the president's voice.\n",
      "Trial 1\n",
      "The statement is fake. The statement is an apparent imitation or digital manipulation of the president's voice.\n",
      "Trial 2\n",
      "The statement is fake. The statement is a clear attempt at voter suppression.\n"
     ]
    }
   ],
   "source": [
    "if False:\n",
    "    statement = 'Joe Biden said not vote.'\n",
    "    context = '''\n",
    "    Fake Joe Biden robocall tells New Hampshire Democrats not to vote Tuesday\n",
    "    The call, an apparent imitation or digital manipulation of the president's voice, says, \"Voting this Tuesday only enables the Republicans in their quest to elect Donald Trump again.\"\n",
    "    \n",
    "    MANCHESTER, N.H. â€” The New Hampshire attorney general's office says it is investigating what appears to be an \"unlawful attempt\" at voter suppression after NBC News reported on a robocall impersonating President Joe Biden that told recipients not to vote in Tuesday's presidential primary.\n",
    "    '''\n",
    "    \n",
    "    for ii in range(0,3):\n",
    "      print(f'Trial {ii}')\n",
    "      output = get_completion_dolly(statement, context)\n",
    "      print(output[0][\"generated_text\"])\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f51474e-aca6-4861-9217-648f7be2f088",
   "metadata": {},
   "source": [
    "### Case 2: A simple statement with the same content in context\n",
    "  * Expect to flag true or I dont know\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d48126b0-2663-481d-95cb-0111d702cff9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "I don't know. I don't know anything about this context.\n",
      "1\n",
      "I don't know. I don't know anything about this context.\n",
      "2\n",
      "I don't know. I don't know anything about this context.\n"
     ]
    }
   ],
   "source": [
    "if False:\n",
    "    statement = 'This is good.'\n",
    "    context = 'This is good.'\n",
    "    \n",
    "    for ii in range(0,3):\n",
    "      print(ii)\n",
    "      output = get_completion_dolly(statement, context)\n",
    "      print(output[0][\"generated_text\"])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d2632c8-d7e6-4738-a039-24d9275b09d2",
   "metadata": {},
   "source": [
    "### Case 3: A true statement with the same content in context\n",
    "  * Expect to flag true"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "4131a7d0-ac07-4863-8ece-8be33cbc666f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "I don't know. I don't know anything about US Presidents.\n",
      "1\n",
      "I don't know. I don't know anything about US Presidents.\n",
      "2\n",
      "I don't know. I don't know anything about US Presidents.\n"
     ]
    }
   ],
   "source": [
    "if False:\n",
    "    statement = 'Joe Biden is the current US President.'\n",
    "    context = statement\n",
    "    \n",
    "    \n",
    "    for ii in range(0,3):\n",
    "      print(ii)\n",
    "      output = get_completion_dolly(statement, context)\n",
    "      print(output[0][\"generated_text\"])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8566090-1057-4120-8e62-a2ea7d2a4dc6",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
